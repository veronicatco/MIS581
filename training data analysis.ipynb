{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f3219db",
   "metadata": {},
   "source": [
    "# Sorghum Cultivar Identification\n",
    "## Analyze Validation Accuracy During Neural Network Training\n",
    "* Veronica Thompson\n",
    "* Colorado State University Global\n",
    "* MIS 581: Capstone\n",
    "* Dr. Orenthio Goodwin\n",
    "* 5/15/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7049d2",
   "metadata": {},
   "source": [
    "This notebook is used to evaluate performance of image classification neural networks on on Sorghum-100 dataset. Graphs are created to visualize training and validation accuracy obtained during neural network training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43497cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa8ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'training histories'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cba01e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_plot(files, title):\n",
    "    fig = plt.figure()\n",
    "    for file, label in files.items():\n",
    "        df = pd.read_csv(os.path.join(path, file))\n",
    "        plt.plot(df['val_accuracy'] * 100, label=label)\n",
    "        fig.suptitle(title, fontsize = 16)\n",
    "        plt.xlabel('Training Epochs')\n",
    "        plt.ylabel('% Accuracy')\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba07003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def side_by_side_plots(files, title):\n",
    "    fig, axes = plt.subplots(1,2)\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.90])\n",
    "    for ax, (file, label) in zip(fig.axes, files.items()):\n",
    "        df = pd.read_csv(os.path.join(path, file))\n",
    "        ax.plot(df['accuracy'] * 100, label='Training Accuracy')\n",
    "        ax.plot(df['val_accuracy'] * 100, label='Validation Accuracy')\n",
    "        ax.set_title(label)\n",
    "        ax.set_xlabel('Training Epochs')\n",
    "        ax.set_ylabel('% Accuracy')\n",
    "        ax.set_ylim(0, 100)\n",
    "        ax.legend()\n",
    "    fig.suptitle(title, fontsize = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f0c836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vs_valid_plot(file, title):\n",
    "    df = pd.read_csv(os.path.join(path,file))\n",
    "    fig = plt.figure()\n",
    "    plt.plot(df['accuracy'] * 100, label='Training Accuracy')\n",
    "    plt.plot(df['val_accuracy'] * 100, label='Validation Accuracy')\n",
    "    fig.suptitle(title, fontsize = 16)\n",
    "    plt.xlabel('Training Epochs')\n",
    "    plt.ylabel('% Accuracy')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4196c6d",
   "metadata": {},
   "source": [
    "### Baseline model\n",
    "The baseline model was trained several times. Validation accuracy after 8 epochs is between .04 and .06 for all trials. The mean accuracy over the five trials was selected as the baseline accuracy. Baseline model included one block of VGG inspired convolution layers and a fully-connect classification layer. The baseline model was trained on images of 128x128 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697de5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {'history 1 layer 128x128.csv': 'run 1',\n",
    "         'history 1 layer 128x128 run2.csv': 'run 2',\n",
    "         'history 1 layer 128x128 run3.csv': 'run 3',\n",
    "         'history 1 layer 128x128 run4.csv': 'run 4',\n",
    "         'history 1 layer 128x128 run5.csv': 'run 5',\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9f1fb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "accuracies = []\n",
    "for file, label in files.items():\n",
    "    df = pd.read_csv(os.path.join(path, file))\n",
    "    plt.plot(df['val_accuracy'] * 100, label=label)\n",
    "    fig.suptitle('Validation Accuracy of Baseline Model')\n",
    "    plt.xlabel('Training Epochs')\n",
    "    plt.ylabel('% Accuracy')\n",
    "    plt.legend()\n",
    "    accuracies += [df['val_accuracy'].iloc[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407eecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_mean_accuracy = sum(accuracies) / len(accuracies)\n",
    "print('Baseline validation accuracy:', baseline_mean_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955d3fc9",
   "metadata": {},
   "source": [
    "### Data augmentation\n",
    "Several methods of data augmentation were examined. Horizontal and vertical shifts of up to 10% and horizontal and vertical shifts showed the most promise. This was the data augmentation used on all candidate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd9bec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {'history 1 layer 128x128 shift 10pct.csv': 'Horizontal and Vertical Shifts',\n",
    "         'history 1 layer 128x128 both flips.csv': 'Horizontal and Vertical Flips',\n",
    "         'history 1 layer 128x128 brightness 50pct.csv': 'Adjust Brightness',\n",
    "         'history 1 layer 128x128 rotate90.csv': 'Rotate up to 90 Degrees'\n",
    "        }\n",
    "single_plot(files, 'Validation Accuracy of Baseline Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5b4fbc",
   "metadata": {},
   "source": [
    "### Reduction in Overfitting\n",
    "The addition of data augmentation reduced overfitting in baseline model. Validation accuracy was increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f85355",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {'history 1 layer 128x128 run2.csv': 'No Data Augmentation',\n",
    "         'history 1 layer 128x128 shift_both_flips.csv': 'With Data Augmentation'\n",
    "        }    \n",
    "side_by_side_plots(files, 'Baseline Model, 128x128 Pixel Images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0743fadc",
   "metadata": {},
   "source": [
    "### Increased Image Size\n",
    "Increasing training images from 128x128 pixels to 224x224 pixels did not result in increased validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa68630",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['one_layer_shiftflip_ep1-50_history.csv',\n",
    "         'one_layer_shiftflip_ep51-70_history.csv',\n",
    "         'one_layer_shiftflip_ep71-80_history.csv']\n",
    "dfs = [pd.read_csv(os.path.join(path, file)) for file in files]\n",
    "df = pd.concat(dfs)\n",
    "df.to_csv(os.path.join(path, 'one_layer_224x224_shift_flip.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a17ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {'layers1_shiftflip_128x128_ep1-90_history.csv': '128x128 Pixels',\n",
    "         'one_layer_224x224_shift_flip.csv': '224x224 Pixels'\n",
    "        }    \n",
    "single_plot(files, 'Baseline Model With Data Augmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415bf588",
   "metadata": {},
   "source": [
    "### Three Block Model\n",
    "The model with three VGG-inspired blocks also benefitted from data augmentation and larger training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f69f139",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {'history 3 layers 128x128.csv': 'No Data Augmentation',\n",
    "         'history 3 layer 128x128 shift_both_flips run2.csv': 'With Data Augmentation'\n",
    "        }\n",
    "side_by_side_plots(files, 'Three Block Model, 128x128 Pixel Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e12581",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['layers3_shiftflip_ep1-40_history.csv',\n",
    "         'layers3_shiftflip_ep41-80_history.csv',\n",
    "         'layers3_shiftflip_ep81-100_history.csv']\n",
    "dfs = [pd.read_csv(os.path.join(path, file)) for file in files]\n",
    "df = pd.concat(dfs)\n",
    "df.to_csv(os.path.join(path, 'three_block_224x224_shift_flip.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e2dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {'history 3 layer 128x128 shift_both_flips run2.csv': '128x128 Pixels',\n",
    "         'three_block_224x224_shift_flip.csv': '224x224 Pixels'\n",
    "        }    \n",
    "single_plot(files, 'Three Block Model with Data Augmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7959bf",
   "metadata": {},
   "source": [
    "### Transfer Learning Using VGG16 Model\n",
    "The pretrained VGG16 model also benefitted from larger training images. Data augmentation was not tested with this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00865113",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {'history vgg16 128x128.csv': '128x128 Pixels',\n",
    "         'vgg16_224x224_ep1-50_history.csv': '224x224 Pixels'\n",
    "        }\n",
    "single_plot(files, \"Pre-trained VGG16 Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f66015d",
   "metadata": {},
   "source": [
    "### Transfer Learning Using ResNet50\n",
    "The ResNet50 model was the most successful of the models which were trained without data augmentation. Despite evidence of overfitting during training, the addition of data augmentation and a much longer training period did little to increase accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd15c55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {'history resnet50 128x128 run2.csv': '128x128 Pixels',\n",
    "         'history resnet50 224x224.csv': '224x224 Pixels'\n",
    "        }\n",
    "single_plot(files, \"Pre-trained ResNet50 Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a53a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'history resnet50 224x224.csv'\n",
    "train_vs_valid_plot(file, 'Pre-trained ResNet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba5552",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['resnet50_shiftflip_ep1-20_history.csv',\n",
    "         'resnet50_shiftflip_ep21-40_history.csv',\n",
    "         'resnet50_shiftflip_ep41-50_history.csv',\n",
    "         'resnet50_shiftflip_ep51-60_history.csv',\n",
    "         'resnet50_shiftflip_ep61-70_history.csv',\n",
    "         'resnet50_shiftflip_ep71-80_history.csv',\n",
    "         'resnet50_shiftflip_ep81-90_history.csv',\n",
    "         'resnet50_shiftflip_ep91-110_history.csv',\n",
    "         'resnet50_shiftflip_ep111-130_history.csv',\n",
    "         'resnet50_shiftflip_ep131-140_history.csv']\n",
    "dfs = [pd.read_csv(os.path.join(path, file)) for file in files]\n",
    "df = pd.concat(dfs)\n",
    "df.to_csv(os.path.join(path, 'resnet50_shift_flip.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297be506",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {'history resnet50 224x224.csv': 'No Data Augmentation',\n",
    "         'resnet50_shift_flip.csv': 'With Data Augmentation'\n",
    "        }\n",
    "side_by_side_plots(files, 'ResNet50 with 224x224 Pixels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c7e52d",
   "metadata": {},
   "source": [
    "### Table of Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a012ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [{'model': 'one_vgg_block', 'aug': 'no', 'size': '128x128',  \n",
    "          'file': 'history 1 layer 128x128 run2.csv'},\n",
    "         {'model': 'one_vgg_block', 'aug': 'no', 'size': '224x224',\n",
    "          'file': 'history 1 layer 224x224.csv'},\n",
    "         {'model': 'one_vgg_block', 'aug': 'yes', 'size': '128x128',  \n",
    "          'file': 'layers1_shiftflip_128x128_ep1-90_history.csv'},\n",
    "         {'model': 'one_vgg_block', 'aug': 'yes', 'size': '224x224',  \n",
    "          'file': 'one_layer_224x224_shift_flip.csv'},\n",
    "         {'model': 'three_vgg_blocks', 'aug': 'no', 'size': '128x128',  \n",
    "          'file': 'history 3 layers 128x128.csv'},\n",
    "         {'model': 'three_vgg_blocks', 'aug': 'yes', 'size': '128x128',  \n",
    "          'file': 'history 3 layer 128x128 shift_both_flips run2.csv'},\n",
    "         {'model': 'three_vgg_blocks', 'aug': 'yes', 'size': '224x224',  \n",
    "          'file': 'three_block_224x224_shift_flip.csv'},\n",
    "         {'model': 'vgg16', 'aug': 'no', 'size': '128x128',  \n",
    "          'file': 'history vgg16 128x128.csv'},\n",
    "         {'model': 'vgg16', 'aug': 'no', 'size': '224x224',  \n",
    "          'file': 'vgg16_224x224_ep1-50_history.csv'},\n",
    "         {'model': 'resnet50', 'aug': 'no', 'size': '128x128',  \n",
    "          'file': 'history resnet50 128x128 run2.csv'},\n",
    "         {'model': 'resnet50', 'aug': 'no', 'size': '224x224',  \n",
    "          'file': 'history resnet50 224x224.csv'},\n",
    "         {'model': 'resnet50', 'aug': 'yes', 'size': '224x224',  \n",
    "          'file': 'resnet50_shift_flip.csv'},\n",
    "        ]\n",
    "df = pd.DataFrame(files)\n",
    "\n",
    "df['val_accuracy'] = df.apply(lambda row : pd.read_csv(os.path.join(path, row['file']))['val_accuracy'].iloc[-1], axis=1)\n",
    "\n",
    "df.drop(columns=['file'], inplace=True)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c230c5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'Baseline': 0,\n",
    "          '3 VGG Blocks\\n224x224 pixels\\nData Augmentation': 6,\n",
    "          'ResNet 50\\n224x224 pixels': 11}\n",
    "labels = list(models.keys())\n",
    "vals = df.iloc[list(models.values())]['val_accuracy'].tolist()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(x=labels, height=vals)\n",
    "ax.set_ylabel('% Accuracy')\n",
    "fig.suptitle('Validation Accuracy for Top Two Models', fontsize = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94d9d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
